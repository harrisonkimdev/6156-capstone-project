{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314783a0-7b32-45ce-a2dc-bfc44acfd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc53b24-c052-43be-a82c-c009fd279b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder_path = \".\\BetaMove\\\\videos\"\n",
    "rawImage_folder_path = \".\\BetaMove\\\\rawImages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac318f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Connor\\\\Documents\\\\1School\\\\AiAndMl\\\\Term2\\\\INFO-6156Capstone\\\\.venv\\\\.venv\\\\BetaMove\\\\videos'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.curdir)\n",
    "#print(os.getcwd()+ \"\\.venv\\BetaMove\\\\videos\")\n",
    "os.getcwd()+ \"\\.venv\\BetaMove\\\\videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b899ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(rawImage_folder_path + \"video01.mp4_frame_0000.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0418c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_every_second(video_path, filename, output_folder, interval_seconds=1.0):\n",
    "    \"\"\"\n",
    "    Extracts one frame per second from a video and saves them as images.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): The path to the input video file.\n",
    "        filename (str): The input video filename.\n",
    "        output_folder (str): The folder where extracted images will be saved.\n",
    "        interval_seconds (float): take a picture every # frames, default is 1 per second\n",
    "    \"\"\"\n",
    "\n",
    "    #Check if output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    full_file_path = video_path + \"\\\\\" + filename\n",
    "    # open the video with cv2\n",
    "    cap = cv2.VideoCapture(full_file_path)\n",
    "\n",
    "    #check if the video opend successifully\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {full_file_path}\")\n",
    "        return\n",
    "    \n",
    "    # get the num fps (24, 30, ect)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    #frame_interval = int(round(fps * interval_seconds))  # frames to skip for desired seconds\n",
    "    frame_interval = int((fps * interval_seconds))  # frames to skip for desired seconds\n",
    "    # print(frame_interval)\n",
    "    if frame_interval <= 0:\n",
    "        frame_interval = 1  # Ensure at least 1 frame step\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_frames_count = 0\n",
    "\n",
    "    while True:\n",
    "        #ret returns true if a frame was read, false when if the video ended or had an error\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        # save the frame every # frames\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Save the frame\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            image_filename = os.path.join(output_folder, f\"{name}_frame_{saved_frames_count:04d}.jpg\")\n",
    "            cv2.imwrite(image_filename, frame)\n",
    "            saved_frames_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted frames every {interval_seconds} seconds\")\n",
    "    print(f\"Extraction complete. {saved_frames_count} frames saved to {output_folder}\")\n",
    "\n",
    "#returns a lower and upper value \n",
    "def make_tolerances(min, max, tolerance, value):\n",
    "    outL = 0\n",
    "    outU = 1\n",
    "\n",
    "    if min > max:\n",
    "        t1 = max\n",
    "        max = min\n",
    "        min = t1\n",
    "    \n",
    "    # set the upper\n",
    "    if value + tolerance > max:\n",
    "        outU = max\n",
    "    else:\n",
    "        outU = value + tolerance\n",
    "    \n",
    "    # set the lower\n",
    "    if value - tolerance < 0:\n",
    "        outL = 0\n",
    "    else:\n",
    "        outL = value - tolerance\n",
    "\n",
    "    #check if upper > lower\n",
    "    if outL > outU:\n",
    "        t1 = outU\n",
    "        outU = outL\n",
    "        outL = t1\n",
    "\n",
    "    return outL, outU\n",
    "\n",
    "# Define tolerance\n",
    "# hue = color\n",
    "# sat = intensity\n",
    "#value = lightness/darkness\n",
    "hue_tol = 5\n",
    "sat_tol = 50\n",
    "val_tol = 40\n",
    "\n",
    "# hue_tol = 1\n",
    "# sat_tol = 1\n",
    "# val_tol = 1\n",
    "\n",
    "# define getters + setters to change the tolerances\n",
    "def get_hue_tol():\n",
    "    return hue_tol\n",
    "def set_hue_tol(tol):\n",
    "    if int(tol) > 0:\n",
    "        hue_tol = int(tol)\n",
    "\n",
    "def get_sat_tol():\n",
    "    return sat_tol\n",
    "def set_sat_tol(tol):\n",
    "    if int(tol) > 0:\n",
    "        sat_tol = int(tol)\n",
    "\n",
    "def get_val_tol():\n",
    "    return val_tol\n",
    "def set_val_tol(tol):\n",
    "    if int(tol) > 0:\n",
    "        val_tol = int(tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9daec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted frames every 0.4 seconds\n",
      "Extraction complete. 39 frames saved to .\\BetaMove\\rawImages\n"
     ]
    }
   ],
   "source": [
    "# use this code block to extract all videos in folder\n",
    "# ##Extract the frames\n",
    "# frame_capture_rate = 0.4\n",
    "# for filename in os.listdir(video_folder_path):\n",
    "#     file_path = os.path.join(video_folder_path, filename)\n",
    "#     print(filename)\n",
    "#     full_file_path = video_folder_path + \"\\\\\" + filename\n",
    "#     extract_frames_every_second(video_folder_path, filename, rawImage_folder_path, frame_capture_rate)\n",
    "\n",
    "# ##Extract the frames\n",
    "# frame_capture_rate = 0.4\n",
    "# file_path = os.path.join(video_folder_path, \"video01.mp4\")\n",
    "# full_file_path = video_folder_path + \"\\\\\" + \"video01.mp4\"\n",
    "# extract_frames_every_second(video_folder_path, \"video01.mp4\", rawImage_folder_path, frame_capture_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d48d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the image to pick a color (press 'q' to quit).\n",
      "pixel Values: [174 175 131]\n",
      "Clicked HSV: [174 175 131], Lower: [169 125  91], Upper: [179 225 171]\n"
     ]
    }
   ],
   "source": [
    "#video01.mp4_frame_0000.jpg\n",
    "hue_tol = 5\n",
    "sat_tol = 50\n",
    "val_tol = 40\n",
    "\n",
    "title_string = \"\"\n",
    "\n",
    "# used for detect_route input + output\n",
    "detect_route_state = {\n",
    "    \"use_image\": None,      # input: input image/mask\n",
    "    \"og_image\": None,       # input: input image/mask\n",
    "    \"in_hsv\": None,         # input: the input hsv \n",
    "    \"hue_tol\": hue_tol,     # input: hue tolerance \n",
    "    \"sat_tol\": sat_tol,     # input: saturation tolerance \n",
    "    \"val_tol\": val_tol,     # input: value tolerance \n",
    "    \"cutout\": None,      # output: the cutout of the route based on a selected pixel\n",
    "    \"mask\": None,        # output: the mask of the route based on a selected pixel\n",
    "    \"p_hsv\": None,       # output: the hsv of the selected pixel\n",
    "    \"x\": None,           # output: the x of the pixel selected\n",
    "    \"y\": None            # output: the y of the pixel selected\n",
    "}\n",
    "\n",
    "def prepare_raw_image(imageName, scale = 0.5):\n",
    "    # Load image\n",
    "    full_image_path = os.path.join(rawImage_folder_path, imageName)\n",
    "    image = cv2.imread(full_image_path)\n",
    "\n",
    "    # resize the image if needed\n",
    "    image = cv2.resize(image, (0, 0), fx=scale, fy=scale)\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) # converts bgr to hsv(hue, sat, value) witch is needed\n",
    "\n",
    "    # Clone for display\n",
    "    display_image01 = image.copy()\n",
    "    return image, display_image01\n",
    "\n",
    "def prepare_image(imageOrMask, scale = 1):\n",
    "    # resize the image if needed\n",
    "    imageOrMask = cv2.resize(imageOrMask, (0, 0), fx=scale, fy=scale)\n",
    "\n",
    "    hsv = cv2.cvtColor(imageOrMask, cv2.COLOR_BGR2HSV) # converts bgr to hsv(hue, sat, value) witch is needed\n",
    "\n",
    "    # Clone for display\n",
    "    display_image02 = imageOrMask.copy()\n",
    "    return imageOrMask, display_image02, hsv\n",
    "\n",
    "def remove_background(image, lower_bg, upper_bg):\n",
    "    \"\"\"\n",
    "    Separates background (whitish-gray) from the foreground.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input BGR image.\n",
    "        lower_bg (list or np.array): Lower HSV bound of background.\n",
    "        upper_bg (list or np.array): Upper HSV bound of background.\n",
    "\n",
    "    Returns:\n",
    "        background_only (numpy.ndarray): Image showing only the background.\n",
    "        foreground_only (numpy.ndarray): Image showing only the foreground.\n",
    "        bg_mask (numpy.ndarray): Binary mask of background.\n",
    "    \"\"\"\n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Make background mask\n",
    "    lower_bg = np.array(lower_bg, dtype=np.uint8)\n",
    "    upper_bg = np.array(upper_bg, dtype=np.uint8)\n",
    "    bg_mask = cv2.inRange(hsv, lower_bg, upper_bg)\n",
    "\n",
    "    # Optional: clean up mask (remove noise, fill holes)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    bg_mask = cv2.morphologyEx(bg_mask, cv2.MORPH_OPEN, kernel)  # remove specks\n",
    "    bg_mask = cv2.morphologyEx(bg_mask, cv2.MORPH_CLOSE, kernel) # close holes\n",
    "\n",
    "    # Extract background & foreground\n",
    "    background_only = cv2.bitwise_and(image, image, mask=bg_mask)\n",
    "    fg_mask = cv2.bitwise_not(bg_mask)\n",
    "    foreground_only = cv2.bitwise_and(image, image, mask=fg_mask)\n",
    "\n",
    "    return background_only, foreground_only, bg_mask\n",
    "mask_filename_global = \"\"\n",
    "def detect_route(event, x, y, flags, param):\n",
    "    title_string = \"\"\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Get HSV value of clicked pixel\n",
    "        pixel_hsv = param[\"in_hsv\"][y, x]\n",
    "        param[\"x\"] = x\n",
    "        param[\"y\"] = y\n",
    "        print(f\"pixel Values: {pixel_hsv}\")\n",
    "\n",
    "        #hue\n",
    "        lower_hue, upper_hue = make_tolerances(0, 179, param[\"hue_tol\"], pixel_hsv[0])\n",
    "        #sat\n",
    "        lower_sat, upper_sat = make_tolerances(0, 255, param[\"sat_tol\"], pixel_hsv[1])\n",
    "        #value\n",
    "        lower_val, upper_val = make_tolerances(0, 255, param[\"val_tol\"], pixel_hsv[2])\n",
    "\n",
    "        lower = np.array([lower_hue,lower_sat,lower_val], dtype=np.uint8) # cast to make sure datatypes are the same\n",
    "        upper = np.array([upper_hue,upper_sat,upper_val], dtype=np.uint8) # cast to make sure datatypes are the same\n",
    "        \n",
    "        # Create mask\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "        # de-noise the mask through opening + closing\n",
    "        kernel = np.ones((3, 3), np.uint8) \n",
    "        # oppend_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        # closed_mask = cv2.morphologyEx(oppend_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # #  to fill any holes in the holds\n",
    "        # kernel = np.ones((5, 5), np.uint8)\n",
    "        # mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # create a cutout (mask + og picture)\n",
    "        cutout = cv2.bitwise_and(param[\"use_image\"], param[\"use_image\"], mask=mask)\n",
    "\n",
    "        # Show updates\n",
    "        mask_filename = os.path.join(rawImage_folder_path, f\"holdsMask.jpg\")\n",
    "        mask_filename_global = mask_filename\n",
    "        cv2.imwrite(mask_filename, mask)\n",
    "        cv2.imshow(\"Mask\", mask)\n",
    "        cv2.imshow(\"Result\", cutout)\n",
    "\n",
    "        print(f\"Clicked HSV: {pixel_hsv}, Lower: {lower}, Upper: {upper}\")\n",
    "        param[\"cutout\"] = cutout\n",
    "        param[\"mask\"] = mask\n",
    "        param[\"p_hsv\"] = pixel_hsv\n",
    "        #return cutout, mask\n",
    "\n",
    "        # draw the boundries on the holds\n",
    "        group_holds(param)\n",
    "\n",
    "def group_holds(param, min_area = 25, max_dist = 150):\n",
    "            # Parameters\n",
    "        min_area = 25\n",
    "        max_dist = 150\n",
    "\n",
    "        # Find contours (white blobs in mask)\n",
    "        contours, _ = cv2.findContours(param[\"mask\"], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        output = param[\"og_image\"].copy()\n",
    "        centers = []\n",
    "\n",
    "        # Step 1: detect blobs(holds) and get centers\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > min_area:\n",
    "                (x, y), radius = cv2.minEnclosingCircle(cnt)\n",
    "                center = (int(x), int(y))\n",
    "                centers.append(center)\n",
    "\n",
    "                cv2.circle(output, center, int(radius), (0, 255, 0), 2)\n",
    "                cv2.putText(output, f\"{int(area)}\", (center[0] - 20, center[1] - 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Step 2: build a single chain starting from a chosen circle (ex. first circle)\n",
    "        used = set()\n",
    "        chain = []\n",
    "        once = True\n",
    "\n",
    "        if centers:\n",
    "            # Find closest center to selected pixel (y = 1000 to start from the bottom)\n",
    "            distances = [(math.dist((param[\"x\"], 1000), center), idx) for idx, center in enumerate(centers)]\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            closest_distance, closest_idx = distances[0]\n",
    "\n",
    "            current_idx = closest_idx            # starting circle (c1)\n",
    "            used.add(current_idx)\n",
    "            chain.append(current_idx)\n",
    "\n",
    "            while True:\n",
    "                c1 = centers[current_idx]\n",
    "                # find closest unused neighbor\n",
    "                distances = [(math.dist(c1, c2), j) for j, c2 in enumerate(centers) if j not in used]\n",
    "                if not distances:\n",
    "                    break  # no unused neighbors left\n",
    "                distances.sort(key=lambda x: x[0])\n",
    "                dist, next_idx = distances[0]\n",
    "                if dist > max_dist:\n",
    "                    break  # next neighbor too far\n",
    "\n",
    "                # draw line\n",
    "                c2 = centers[next_idx]\n",
    "                #cv2.line(output, c1, c2, (255, 0, 0), 2)\n",
    "                cv2.arrowedLine(output, c1, c2, (255, 0, 0), 2, tipLength=0.2)\n",
    "\n",
    "                # move to next circle\n",
    "                used.add(next_idx)\n",
    "                chain.append(next_idx)\n",
    "                current_idx = next_idx\n",
    "\n",
    "                cv2.imshow(\"Chained Connections\", output)\n",
    "                image_filename = os.path.join(rawImage_folder_path, f\"outPutWtConnections.jpg\")\n",
    "                cv2.imwrite(image_filename, output)\n",
    "\n",
    "lower_bg = [0, 0, 104]\n",
    "upper_bg = [178, 33, 244]\n",
    "\n",
    "useImage, display_image01 = prepare_raw_image(\"video01_frame_0000.jpg\")\n",
    "# useImage, display_image01 = prepare_raw_image(\"video01_3_frame_0000.jpg\")\n",
    "background_only, foreground_only, bg_mask = remove_background(useImage, lower_bg, upper_bg)\n",
    "\n",
    "lower_bg = [96, 138, 124]\n",
    "upper_bg = [106, 238, 204]\n",
    "\n",
    "background_only, foreground_only, bg_mask = remove_background(foreground_only, lower_bg, upper_bg)\n",
    "\n",
    "useImage, display_image02, hsv = prepare_image(foreground_only)\n",
    "\n",
    "image_filename = os.path.join(rawImage_folder_path, f\"outPuForground.jpg\")\n",
    "cv2.imwrite(image_filename, useImage)\n",
    "\n",
    "detect_route_state[\"use_image\"] = useImage\n",
    "detect_route_state[\"og_image\"] = display_image01\n",
    "detect_route_state[\"in_hsv\"] = hsv\n",
    "\n",
    "\n",
    "cv2.imshow(f\"Image\", display_image02)\n",
    "\n",
    "cv2.setMouseCallback(f\"Image\", detect_route, detect_route_state)\n",
    "\n",
    "\n",
    "#group_holds(detect_route_state[\"mask\"])\n",
    "\n",
    "# Show original image\n",
    "# cv2.imshow(f\"Image\", display_image)\n",
    "# cv2.setMouseCallback(f\"Image\", mouse_callback)\n",
    "\n",
    "print(\"Click on the image to pick a color (press 'q' to quit).\")\n",
    "\n",
    "def update_title():\n",
    "    t1 = {detect_route_state[\"p_hsv\"]}\n",
    "    cv2.setWindowTitle(\"Image\", f\"Image - Mode: {title_string} : HVS {hue_tol},{val_tol},{sat_tol}, Pixel value = {t1}\")\n",
    "\n",
    "update_title()  # set initial title\n",
    "\n",
    "# Start in hue mode by default\n",
    "mode = \"h\"   # can be \"h\", \"s\", or \"v\"\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "\n",
    "    if key == ord('q'):   # Quit\n",
    "        break\n",
    "\n",
    "    # # --- Switch modes ---\n",
    "    # elif key == ord('h'):\n",
    "    #     mode = \"h\"\n",
    "    #     print(\"Mode: Hue tolerance\")\n",
    "    #     title_string = \"Hue\"\n",
    "    #     update_title()\n",
    "    # elif key == ord('v'):\n",
    "    #     mode = \"v\"\n",
    "    #     print(\"Mode: Value tolerance\")\n",
    "    #     title_string = \"Value\"\n",
    "    #     update_title()\n",
    "    # elif key == ord('s'):\n",
    "    #     mode = \"s\"\n",
    "    #     print(\"Mode: Saturation tolerance\")\n",
    "    #     title_string = \"Sat\"\n",
    "    #     update_title()\n",
    "\n",
    "    # # --- Adjust based on mode ---\n",
    "    # elif key == ord('='):   # '+' key\n",
    "    #     if mode == \"h\":\n",
    "    #         hue_tol = min(hue_tol + 1, 179)\n",
    "    #         print(f\"Hue tolerance increased to {hue_tol}\")\n",
    "    #     elif mode == \"s\":\n",
    "    #         sat_tol = min(sat_tol + 1, 255)\n",
    "    #         print(f\"Saturation tolerance increased to {sat_tol}\")\n",
    "    #     elif mode == \"v\":\n",
    "    #         val_tol = min(val_tol + 1, 255)\n",
    "    #         print(f\"Value tolerance increased to {val_tol}\")\n",
    "    #     update_title()\n",
    "\n",
    "    # elif key == ord('-'):   # '-' key\n",
    "    #     if mode == \"h\":\n",
    "    #         hue_tol = max(hue_tol - 1, 0)\n",
    "    #         print(f\"Hue tolerance decreased to {hue_tol}\")\n",
    "    #     elif mode == \"s\":\n",
    "    #         sat_tol = max(sat_tol - 1, 0)\n",
    "    #         print(f\"Saturation tolerance decreased to {sat_tol}\")\n",
    "    #     elif mode == \"v\":\n",
    "    #         val_tol = max(val_tol - 1, 0)\n",
    "    #         print(f\"Value tolerance decreased to {val_tol}\")\n",
    "    #     update_title()\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows() # kill the popout windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0286f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
