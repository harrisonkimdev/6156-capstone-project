{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf437c3",
   "metadata": {},
   "source": [
    "# 6156 Capstone Project\n",
    "\n",
    "Group 5: Connor Lynch, Harrison Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4abe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '6156-capstone-project'...\n",
      "remote: Enumerating objects: 80, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Enumerating objects: 80, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 80 (delta 1), reused 5 (delta 0), pack-reused 68 (from 2)\u001b[K\n",
      "Receiving objects: 100% (80/80), 79.21 MiB | 42.71 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n",
      "remote: Total 80 (delta 1), reused 5 (delta 0), pack-reused 68 (from 2)\u001b[K\n",
      "Receiving objects: 100% (80/80), 79.21 MiB | 42.71 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n",
      "/Users/harrisonkim/code/repos/6156-capstone-project/notebooks/6156-capstone-project\n",
      "Cloned Repository!\n",
      "Current location: /Users/harrisonkim/code/repos/6156-capstone-project/notebooks/6156-capstone-project\n",
      "/Users/harrisonkim/code/repos/6156-capstone-project/notebooks/6156-capstone-project\n",
      "Cloned Repository!\n",
      "Current location: /Users/harrisonkim/code/repos/6156-capstone-project/notebooks/6156-capstone-project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/6156/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# Clone directly from GitHub\n",
    "!git clone https://github.com/harrisonkimdev/6156-capstone-project.git\n",
    "%cd 6156-capstone-project\n",
    "\n",
    "import os\n",
    "print(\"Cloned Repository!\")\n",
    "print(f\"Current location: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f943e02",
   "metadata": {},
   "source": [
    "## Install required packages and configure pose_ai module path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0969212",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "⚠️ Warning: src folder not found: /Users/harrisonkim/code/repos/6156-capstone-project/notebooks/6156-capstone-project/src\n",
      "   Please ensure the repository is cloned or src/ folder exists.\n",
      "✗ pose_ai import failed: No module named 'pose_ai'\n",
      "  Solutions:\n",
      "  1. Verify the repository is cloned correctly\n",
      "  2. Check if src/pose_ai/ folder exists\n",
      "  3. Refer to \"How to Use in Google Colab\" cell above for repo setup\n",
      "\n",
      "Current working directory: /Users/harrisonkim/code/repos/6156-capstone-project/notebooks/6156-capstone-project\n",
      "src added to Python path: N/A\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "⚠️ Warning: src folder not found: /Users/harrisonkim/code/repos/6156-capstone-project/notebooks/6156-capstone-project/src\n",
      "   Please ensure the repository is cloned or src/ folder exists.\n",
      "✗ pose_ai import failed: No module named 'pose_ai'\n",
      "  Solutions:\n",
      "  1. Verify the repository is cloned correctly\n",
      "  2. Check if src/pose_ai/ folder exists\n",
      "  3. Refer to \"How to Use in Google Colab\" cell above for repo setup\n",
      "\n",
      "Current working directory: /Users/harrisonkim/code/repos/6156-capstone-project/notebooks/6156-capstone-project\n",
      "src added to Python path: N/A\n"
     ]
    }
   ],
   "source": [
    "# 1. Install packages\n",
    "%pip install -q --upgrade pip\n",
    "%pip install -q numpy pandas scikit-learn xgboost opencv-python mediapipe\n",
    "\n",
    "# 2. Configure path to import pose_ai module\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src folder to Python path\n",
    "repo_root = Path.cwd()\n",
    "src_path = repo_root / 'src'\n",
    "\n",
    "if src_path.exists():\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.insert(0, str(src_path))\n",
    "    os.environ.setdefault('PYTHONPATH', str(src_path) + (':' + os.environ.get('PYTHONPATH', '')))\n",
    "    print(f\"✓ src path added: {src_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ Warning: src folder not found: {src_path}\")\n",
    "    print(\"   Please ensure the repository is cloned or src/ folder exists.\")\n",
    "\n",
    "# 3. Verify pose_ai import\n",
    "try:\n",
    "    import pose_ai as _pose_ai\n",
    "    print(f'✓ pose_ai module imported successfully! (version: {getattr(_pose_ai, \"__version__\", \"unknown\")})')\n",
    "except Exception as e:\n",
    "    print(f'✗ pose_ai import failed: {e}')\n",
    "    print('  Solutions:')\n",
    "    print('  1. Verify the repository is cloned correctly')\n",
    "    print('  2. Check if src/pose_ai/ folder exists')\n",
    "    print('  3. Refer to \"How to Use in Google Colab\" cell above for repo setup')\n",
    "\n",
    "# Display current working directory\n",
    "print(f\"\\nCurrent working directory: {Path.cwd()}\")\n",
    "print(f\"src added to Python path: {str(src_path) if src_path.exists() else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts Python Collection\n",
    "\n",
    "This notebook aggregates the Python scripts from the `scripts` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts/extract_frames.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CLI for extracting frame sequences from climbing videos.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from pose_ai.data import FrameExtractionResult, extract_frames_every_n_seconds, iter_video_files\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(\"pose_ai.scripts.extract_frames\")\n",
    "\n",
    "\n",
    "def configure_logging(verbose: bool) -> None:\n",
    "    level = logging.DEBUG if verbose else logging.INFO\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_from_directory(\n",
    "    source_dir: Path,\n",
    "    *,\n",
    "    output_root: Path,\n",
    "    interval_seconds: float,\n",
    "    recursive: bool,\n",
    "    overwrite: bool,\n",
    "    write_manifest: bool,\n",
    ") -> list[FrameExtractionResult]:\n",
    "    results: list[FrameExtractionResult] = []\n",
    "    for video_path in iter_video_files(source_dir, recursive=recursive):\n",
    "        LOGGER.info(\"Processing %s\", video_path)\n",
    "        result = extract_frames_every_n_seconds(\n",
    "            video_path,\n",
    "            interval_seconds=interval_seconds,\n",
    "            output_root=output_root,\n",
    "            write_manifest=write_manifest,\n",
    "            overwrite=overwrite,\n",
    "        )\n",
    "        LOGGER.info(\n",
    "            \"Saved %d frames for %s\",\n",
    "            result.saved_frames,\n",
    "            video_path.name,\n",
    "        )\n",
    "        results.append(result)\n",
    "    if not results:\n",
    "        LOGGER.warning(\"No video files found in %s\", source_dir)\n",
    "    return results\n",
    "\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Extract frame sequences from climbing videos.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"video_dir\",\n",
    "        type=Path,\n",
    "        help=\"Directory containing source video files.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        type=Path,\n",
    "        default=Path(\"data\") / \"frames\",\n",
    "        help=\"Directory where frame folders will be stored.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--interval\",\n",
    "        type=float,\n",
    "        default=1.0,\n",
    "        help=\"Seconds between captured frames (default: 1.0).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--recursive\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Search for videos recursively.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overwrite\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Overwrite existing extracted frames.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-manifest\",\n",
    "        dest=\"write_manifest\",\n",
    "        action=\"store_false\",\n",
    "        help=\"Disable writing manifest.json files.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--verbose\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Enable verbose logging.\",\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = build_parser()\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    configure_logging(verbose=args.verbose)\n",
    "    extract_from_directory(\n",
    "        args.video_dir,\n",
    "        output_root=args.output,\n",
    "        interval_seconds=args.interval,\n",
    "        recursive=args.recursive,\n",
    "        overwrite=args.overwrite,\n",
    "        write_manifest=args.write_manifest,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts/run_feature_export.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CLI to export pose-derived features from manifests.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from pose_ai.service import export_features_for_manifest\n",
    "\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser(description=\"Export pose feature rows from pose_results.json.\")\n",
    "    parser.add_argument(\"manifest\", type=Path, help=\"Path to manifest.json\")\n",
    "    parser.add_argument(\n",
    "        \"--holds\",\n",
    "        type=Path,\n",
    "        help=\"Optional JSON describing holds (name -> coords, normalized, etc).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--out\",\n",
    "        type=Path,\n",
    "        default=None,\n",
    "        help=\"Output directory (defaults to manifest directory).\",\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = build_parser()\n",
    "    args = parser.parse_args()\n",
    "    output_path = export_features_for_manifest(\n",
    "        args.manifest,\n",
    "        holds_path=args.holds,\n",
    "        output_root=args.out,\n",
    "    )\n",
    "    print(f\"Feature rows saved to {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts/run_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"End-to-end pipeline: extract frames, run pose estimation, features, segments, visualize.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_DIR = Path(__file__).resolve().parents[1]\n",
    "SRC_DIR = ROOT_DIR / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "from pose_ai.service import (  # type: ignore  # pylint: disable=wrong-import-position\n",
    "    estimate_poses_from_manifest,\n",
    "    export_features_for_manifest,\n",
    "    generate_segment_report,\n",
    ")\n",
    "from extract_frames import extract_frames_every_n_seconds, iter_video_files  # type: ignore\n",
    "from visualize_pose import visualize_pose_results  # type: ignore\n",
    "\n",
    "# NOTE: For simplicity we call into script helpers directly for pose/feature export\n",
    "# and reuse service APIs for intermediate steps.\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser(description=\"Run entire pose analysis pipeline\")\n",
    "    parser.add_argument(\"video_dir\", type=Path, help=\"Directory containing videos (.mp4, etc.)\")\n",
    "    parser.add_argument(\"--out\", type=Path, default=Path(\"data/frames\"), help=\"Frame output directory\")\n",
    "    parser.add_argument(\"--interval\", type=float, default=1.0, help=\"Extraction interval (seconds)\")\n",
    "    parser.add_argument(\"--skip-visuals\", action=\"store_true\", help=\"Skip visualization step\")\n",
    "    return parser\n",
    "\n",
    "\n",
    "def extract_frames(video_dir: Path, out_dir: Path, interval: float) -> list[Path]:\n",
    "    manifests = []\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for video_file in iter_video_files(video_dir):\n",
    "        result = extract_frames_every_n_seconds(video_file, output_root=out_dir, interval_seconds=interval)\n",
    "        manifests.append(result.frame_directory / \"manifest.json\")\n",
    "    return manifests\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = build_parser()\n",
    "    args = parser.parse_args()\n",
    "    manifests = extract_frames(args.video_dir, args.out, args.interval)\n",
    "    for manifest in manifests:\n",
    "        print(f\"Processing manifest {manifest}\")\n",
    "        estimate_poses_from_manifest(manifest)\n",
    "        export_features_for_manifest(manifest)\n",
    "        generate_segment_report(manifest)\n",
    "        if not args.skip_visuals:\n",
    "            frame_dir = manifest.parent\n",
    "            visualize_pose_results(frame_dir / \"pose_results.json\")\n",
    "    print(\"Pipeline completed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts/run_pose_estimation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CLI to run pose estimation on extracted frame sequences.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from pose_ai.pose import PoseEstimator\n",
    "from pose_ai.service import estimate_poses_for_directory, estimate_poses_from_manifest\n",
    "\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser(description=\"Run MediaPipe pose estimation on frame manifests.\")\n",
    "    group = parser.add_mutually_exclusive_group(required=True)\n",
    "    group.add_argument(\"--manifest\", type=Path, help=\"Path to a manifest.json file.\")\n",
    "    group.add_argument(\"--frames-root\", type=Path, help=\"Directory containing extracted frame folders.\")\n",
    "    parser.add_argument(\n",
    "        \"--json\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Print pose results as JSON instead of a textual summary.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-save\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Disable writing pose_results.json files alongside frames.\",\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def frames_to_dict(frames):\n",
    "    return [\n",
    "        {\n",
    "            \"image_path\": str(frame.image_path),\n",
    "            \"timestamp_seconds\": frame.timestamp_seconds,\n",
    "            \"detection_score\": frame.detection_score,\n",
    "            \"landmarks\": [\n",
    "                {\n",
    "                    \"name\": landmark.name,\n",
    "                    \"x\": landmark.x,\n",
    "                    \"y\": landmark.y,\n",
    "                    \"z\": landmark.z,\n",
    "                    \"visibility\": landmark.visibility,\n",
    "                }\n",
    "                for landmark in frame.landmarks\n",
    "            ],\n",
    "        }\n",
    "        for frame in frames\n",
    "    ]\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = build_parser()\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    estimator = PoseEstimator()\n",
    "    try:\n",
    "        if args.manifest:\n",
    "            frames = estimate_poses_from_manifest(\n",
    "                args.manifest,\n",
    "                estimator=estimator,\n",
    "                save_json=not args.no_save,\n",
    "            )\n",
    "            if args.json:\n",
    "                print(json.dumps(frames_to_dict(frames), indent=2))\n",
    "            else:\n",
    "                print(f\"Processed {len(frames)} frames from {args.manifest}\")\n",
    "        else:\n",
    "            results = estimate_poses_for_directory(\n",
    "                args.frames_root,\n",
    "                estimator=estimator,\n",
    "                save_json=not args.no_save,\n",
    "            )\n",
    "            if args.json:\n",
    "                payload = {manifest: frames_to_dict(frames) for manifest, frames in results.items()}\n",
    "                print(json.dumps(payload, indent=2))\n",
    "            else:\n",
    "                for manifest, frames in results.items():\n",
    "                    print(f\"{manifest}: {len(frames)} frames\")\n",
    "    except ModuleNotFoundError as exc:\n",
    "        parser.error(\n",
    "            f\"{exc}. Ensure mediapipe is installed in your environment (e.g. `pip install mediapipe`).\"\n",
    "        )\n",
    "    finally:\n",
    "        estimator.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts/run_segment_report.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CLI to generate segment-level metrics.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "\n",
    "from pose_ai.service import generate_segment_report\n",
    "\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser(description=\"Export segment metrics (COM, joints, contacts)\")\n",
    "    parser.add_argument(\"manifest\", type=str, help=\"Path to manifest.json\")\n",
    "    parser.add_argument(\"--holds\", type=str, help=\"Optional holds JSON path\", default=None)\n",
    "    return parser\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = build_parser()\n",
    "    args = parser.parse_args()\n",
    "    metrics = generate_segment_report(args.manifest, holds_path=Path(args.holds) if args.holds else None)\n",
    "    print(f\"Saved {len(metrics)} segments\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts/run_segmentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CLI to run rule-based segmentation over extracted frame manifests.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from pose_ai.service import segment_video_from_manifest, segment_videos_under_directory\n",
    "\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser(description=\"Produce rest/movement segments from frame manifests.\")\n",
    "    group = parser.add_mutually_exclusive_group(required=True)\n",
    "    group.add_argument(\"--manifest\", type=Path, help=\"Path to a manifest.json file.\")\n",
    "    group.add_argument(\"--frames-root\", type=Path, help=\"Directory containing subfolders with manifest.json files.\")\n",
    "    parser.add_argument(\"--json\", action=\"store_true\", help=\"Print segmentation results as JSON.\")\n",
    "    return parser\n",
    "\n",
    "\n",
    "def _segment_to_dict(segment):\n",
    "    return {\n",
    "        \"start_time\": segment.start_time,\n",
    "        \"end_time\": segment.end_time,\n",
    "        \"label\": segment.label,\n",
    "        \"duration\": segment.duration,\n",
    "        \"frame_indices\": segment.frame_indices,\n",
    "    }\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = build_parser()\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.manifest:\n",
    "        segments = segment_video_from_manifest(args.manifest)\n",
    "        if args.json:\n",
    "            print(json.dumps([_segment_to_dict(seg) for seg in segments], indent=2))\n",
    "        else:\n",
    "            print(f\"Segments for {args.manifest}:\")\n",
    "            for seg in segments:\n",
    "                print(\n",
    "                    f\"- {seg.label:9s} {seg.start_time:5.2f}s → {seg.end_time:5.2f}s \"\n",
    "                    f\"(duration {seg.duration:4.2f}s, frames {seg.frame_indices})\"\n",
    "                )\n",
    "    else:\n",
    "        results = segment_videos_under_directory(args.frames_root)\n",
    "        if args.json:\n",
    "            payload = {\n",
    "                manifest: [_segment_to_dict(seg) for seg in segments]\n",
    "                for manifest, segments in results.items()\n",
    "            }\n",
    "            print(json.dumps(payload, indent=2))\n",
    "        else:\n",
    "            for manifest, segments in results.items():\n",
    "                print(f\"Segments for {manifest}:\")\n",
    "                for seg in segments:\n",
    "                    print(\n",
    "                        f\"  - {seg.label:9s} {seg.start_time:5.2f}s → {seg.end_time:5.2f}s \"\n",
    "                        f\"(duration {seg.duration:4.2f}s, frames {seg.frame_indices})\"\n",
    "                    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts/train_xgboost.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train an XGBoost model on pose feature data (CLI).\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "from pose_ai.ml.xgb_trainer import TrainParams, params_from_dict, train_from_file\n",
    "\n",
    "\n",
    "def _parse_args() -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser(description=\"Train XGBoost on pose feature rows.\")\n",
    "    parser.add_argument(\"features\", type=Path, help=\"Path to pose_features.json\")\n",
    "\n",
    "    # Data/label\n",
    "    parser.add_argument(\"--label-column\", default=\"detection_score\")\n",
    "    parser.add_argument(\"--label-threshold\", type=float, default=None)\n",
    "    parser.add_argument(\"--drop-columns\", nargs=\"*\", default=[\"image_path\"])\n",
    "    parser.add_argument(\"--task\", choices=[\"classification\", \"regression\"], default=\"classification\")\n",
    "    parser.add_argument(\"--test-size\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--random-state\", type=int, default=42)\n",
    "\n",
    "    # XGBoost hyperparameters\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=300)\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--max-depth\", type=int, default=4)\n",
    "    parser.add_argument(\"--subsample\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--colsample-bytree\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--scale-pos-weight\", type=float, default=None)\n",
    "    parser.add_argument(\"--n-jobs\", type=int, default=0)\n",
    "    parser.add_argument(\"--tree-method\", default=None, help=\"e.g., hist or gpu_hist\")\n",
    "\n",
    "    # Training behaviour\n",
    "    parser.add_argument(\"--early-stopping-rounds\", type=int, default=30)\n",
    "    parser.add_argument(\"--eval-metric-cls\", default=\"logloss\")\n",
    "    parser.add_argument(\"--eval-metric-reg\", default=\"rmse\")\n",
    "\n",
    "    # Outputs\n",
    "    parser.add_argument(\"--model-out\", type=Path, default=Path(\"models/xgb_pose.json\"))\n",
    "    parser.add_argument(\"--metrics-out\", type=Path, default=None)\n",
    "    parser.add_argument(\"--feature-out\", type=Path, default=None)\n",
    "    parser.add_argument(\"--importance-out\", type=Path, default=None)\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    args = _parse_args()\n",
    "    params = params_from_dict(\n",
    "        {\n",
    "            \"task\": args.task,\n",
    "            \"label_column\": args.label_column,\n",
    "            \"label_threshold\": args.label_threshold,\n",
    "            \"drop_columns\": args.drop_columns,\n",
    "            \"test_size\": args.test_size,\n",
    "            \"random_state\": args.random_state,\n",
    "            \"n_estimators\": args.n_estimators,\n",
    "            \"learning_rate\": args.learning_rate,\n",
    "            \"max_depth\": args.max_depth,\n",
    "            \"subsample\": args.subsample,\n",
    "            \"colsample_bytree\": args.colsample_bytree,\n",
    "            \"scale_pos_weight\": args.scale_pos_weight,\n",
    "            \"n_jobs\": args.n_jobs,\n",
    "            \"tree_method\": args.tree_method,\n",
    "            \"early_stopping_rounds\": args.early_stopping_rounds,\n",
    "            \"eval_metric_cls\": args.eval_metric_cls,\n",
    "            \"eval_metric_reg\": args.eval_metric_reg,\n",
    "            \"model_out\": args.model_out,\n",
    "            \"metrics_out\": args.metrics_out,\n",
    "            \"feature_out\": args.feature_out,\n",
    "            \"importance_out\": args.importance_out,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    metrics = train_from_file(args.features, params)\n",
    "    print(f\"Model saved to {params.model_out}\")\n",
    "    print(\"Metrics:\", metrics)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts/visualize_pose.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate pose visualization overlays from pose_results.json.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "try:  # optional dependency for connection definitions\n",
    "    from mediapipe.python.solutions.pose import PoseLandmark, POSE_CONNECTIONS\n",
    "except ModuleNotFoundError:  # fallback if mediapipe not installed\n",
    "    PoseLandmark = None\n",
    "    POSE_CONNECTIONS = []\n",
    "\n",
    "\n",
    "DEFAULT_CONNECTIONS = [\n",
    "    (\"left_shoulder\", \"right_shoulder\"),\n",
    "    (\"left_shoulder\", \"left_elbow\"),\n",
    "    (\"left_elbow\", \"left_wrist\"),\n",
    "    (\"right_shoulder\", \"right_elbow\"),\n",
    "    (\"right_elbow\", \"right_wrist\"),\n",
    "    (\"left_hip\", \"right_hip\"),\n",
    "    (\"left_shoulder\", \"left_hip\"),\n",
    "    (\"right_shoulder\", \"right_hip\"),\n",
    "    (\"left_hip\", \"left_knee\"),\n",
    "    (\"left_knee\", \"left_ankle\"),\n",
    "    (\"right_hip\", \"right_knee\"),\n",
    "    (\"right_knee\", \"right_ankle\"),\n",
    "]\n",
    "\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser(description=\"Visualize pose landmarks on extracted frames.\")\n",
    "    parser.add_argument(\"pose_results\", type=Path, help=\"Path to pose_results.json\")\n",
    "    parser.add_argument(\n",
    "        \"--output\", type=Path, default=None,\n",
    "        help=\"Directory to write visualized images (defaults to frame directory).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--include-missing\", action=\"store_true\",\n",
    "        help=\"Include frames even when detection score/visibility is low.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-score\",\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help=\"Minimum frame detection score required for visualization (default: 0.3).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-visibility\",\n",
    "        type=float,\n",
    "        default=0.2,\n",
    "        help=\"Minimum landmark visibility to draw a point/connection (default: 0.2).\",\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def _get_connections():\n",
    "    if PoseLandmark is None or not POSE_CONNECTIONS:\n",
    "        return DEFAULT_CONNECTIONS\n",
    "    connections = []\n",
    "    for a_idx, b_idx in POSE_CONNECTIONS:\n",
    "        connections.append((PoseLandmark(a_idx).name.lower(), PoseLandmark(b_idx).name.lower()))\n",
    "    return connections\n",
    "\n",
    "\n",
    "def visualize_pose_results(\n",
    "    pose_results_path: Path,\n",
    "    output_dir: Path | None = None,\n",
    "    *,\n",
    "    include_missing: bool = False,\n",
    "    min_score: float = 0.3,\n",
    "    min_visibility: float = 0.2,\n",
    ") -> int:\n",
    "    payload = json.loads(pose_results_path.read_text(encoding=\"utf-8\"))\n",
    "    frames = payload.get(\"frames\", [])\n",
    "    count = 0\n",
    "    connections = _get_connections()\n",
    "\n",
    "    for frame in frames:\n",
    "        image_path = Path(frame[\"image_path\"])\n",
    "        image = cv2.imread(str(image_path))\n",
    "        if image is None:\n",
    "            continue\n",
    "        height, width = image.shape[:2]\n",
    "        landmarks = frame.get(\"landmarks\", [])\n",
    "        detection_score = float(frame.get(\"detection_score\", 0.0))\n",
    "        if not include_missing and detection_score < min_score:\n",
    "            continue\n",
    "        if not landmarks and not include_missing:\n",
    "            continue\n",
    "\n",
    "        points = {}\n",
    "        for landmark in landmarks:\n",
    "            x = int(landmark[\"x\"] * width)\n",
    "            y = int(landmark[\"y\"] * height)\n",
    "            if landmark.get(\"visibility\", 1.0) < min_visibility:\n",
    "                continue\n",
    "            points[landmark[\"name\"]] = (x, y)\n",
    "            cv2.circle(image, (x, y), 4, (0, 255, 0), -1)\n",
    "\n",
    "        for start, end in connections:\n",
    "            if start in points and end in points:\n",
    "                cv2.line(image, points[start], points[end], (255, 0, 0), 2)\n",
    "\n",
    "        target_dir = output_dir or image_path.parent / \"visualized\"\n",
    "        target_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = target_dir / f\"{image_path.stem}_viz{image_path.suffix}\"\n",
    "        cv2.imwrite(str(out_path), image)\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = build_parser()\n",
    "    args = parser.parse_args()\n",
    "    processed = visualize_pose_results(\n",
    "        args.pose_results,\n",
    "        args.output,\n",
    "        include_missing=args.include_missing,\n",
    "        min_score=args.min_score,\n",
    "        min_visibility=args.min_visibility,\n",
    "    )\n",
    "    print(f\"Saved {processed} annotated frames\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6156 (py3.10)",
   "language": "python",
   "name": "6156"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
